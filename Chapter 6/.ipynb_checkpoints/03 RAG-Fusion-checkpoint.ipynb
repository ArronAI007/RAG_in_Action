{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3445c65c-9a2f-44bd-ac16-7c439918cb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载 .env 文件中的OpenAI API环境变量\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a00e71-e9d1-4d19-9cea-7dc804832d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "# 初始化向量数据库\n",
    "def initialize_faiss_vectorstore(file_paths):\n",
    "    # 1. 加载文档\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        loader = TextLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        documents.extend(docs)\n",
    "\n",
    "    # 2. 分割文档\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # 3. 初始化嵌入模型\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # 4. 创建并初始化FAISS向量数据库\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# 定义多重查询生成器\n",
    "def generate_queries(original_query):\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"You are a helpful assistant that generates multiple search queries based on a single input query.\\n\\nGenerate multiple search queries related to: {question}\\n\\nOutput (4 queries):\"\n",
    "    )\n",
    "    chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "    queries = chain.invoke({\"question\": original_query})[\"text\"].split(\"\\n\")\n",
    "    return queries\n",
    "\n",
    "# 定义倒数排名融合算法\n",
    "def reciprocal_rank_fusion(results, k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = str(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results\n",
    "\n",
    "# 定义完整的 RAG-Fusion 链\n",
    "def rag_fusion_chain(original_query):\n",
    "    # 生成多重查询\n",
    "    queries = generate_queries(original_query)\n",
    "    \n",
    "    # 对每个查询进行向量搜索\n",
    "    results = []\n",
    "    for query in queries:\n",
    "        docs = vectorstore.similarity_search(query, k=4)\n",
    "        results.append(docs)\n",
    "    \n",
    "    # 使用 RRF 算法对文档进行重新排序\n",
    "    reranked_results = reciprocal_rank_fusion(results)\n",
    "    \n",
    "    # 提取重排序后的文档内容\n",
    "    top_docs = [doc[0].page_content for doc in reranked_results[:4]]\n",
    "    \n",
    "    # 生成最终答案\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Answer the following question based on this context:\\n{context}\\nQuestion: {question}\\n\"\n",
    "    )\n",
    "    chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "    answer = chain.invoke({\"context\": \"\\n\".join(top_docs), \"question\": original_query})\n",
    "    return answer\n",
    "\n",
    "# 示例问题\n",
    "original_query = \"示例查询内容\"\n",
    "file_paths = [\"doc1.txt\", \"doc2.txt\", \"doc3.txt\"]\n",
    "vectorstore = initialize_faiss_vectorstore(file_paths)\n",
    "result = rag_fusion_chain(original_query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675abe73-db08-4249-ba0f-77c0cf754e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_book",
   "language": "python",
   "name": "rag_book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
